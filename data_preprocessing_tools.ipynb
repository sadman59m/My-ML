{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnfGz76p2z/uCvQ4d+upKh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadman59m/My-ML/blob/main/data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "2uItvV_6rFH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "j_oNf2Aiqm58"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Data.csv')\n",
        "# X is the independent or featuer , Y is the dependent variable\n",
        "# in the X, the the firest 3 cols with all rows\n",
        "X = dataset.iloc[:, :-1].values\n",
        "# Y the last col with all rows\n",
        "Y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "eDhXuQAnrXs6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_cols = []\n",
        "for index, x in enumerate(X[0]):\n",
        "  if type(x) == float or type(x) == int:\n",
        "    n_cols.append(index)\n",
        "numeric_x = X[:, n_cols]\n",
        "print(numeric_x)"
      ],
      "metadata": {
        "id": "1p180Zngv2Fw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c45b61-ca18-4324-bc71-642c81f27d82"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[44.0 72000.0]\n",
            " [27.0 48000.0]\n",
            " [30.0 54000.0]\n",
            " [38.0 61000.0]\n",
            " [40.0 nan]\n",
            " [35.0 58000.0]\n",
            " [nan 52000.0]\n",
            " [48.0 79000.0]\n",
            " [50.0 83000.0]\n",
            " [37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Missing Values\n",
        "Generally we replace the missing values with average of all values. We do this in numerical columns"
      ],
      "metadata": {
        "id": "5MNApHEJ06kI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use scikit learn to perform it\n",
        "from sklearn.impute import SimpleImputer\n",
        "# np.nan means the numpy nun values\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "# pass all the cols of X with numerical values\n",
        "# in X, 2nd and 3rd cols with all the rows\n",
        "imputer.fit(X[:, 1:3])\n",
        "# replace the X with new transformed X cols. The values are replaced with average\n",
        "X[: , 1:3] = imputer.transform(X[:, 1:3])\n",
        "print(X)"
      ],
      "metadata": {
        "id": "dGoqKuziwBM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e137f78b-abb1-40fb-fbbb-c0b48856064e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding Categorycal Data\n",
        "Means representing the Text Data colums with numeircal Data."
      ],
      "metadata": {
        "id": "lRN3lUj34ZMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Indepent Variable \\\n",
        "here, France, Spain, Gernamy\\\n",
        "Values are assigned as 0.0 0.1 1.0 to prevent squilization of 0, 1, 2 which will mislead the model"
      ],
      "metadata": {
        "id": "MtSLy_sd4kzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# transformers is an array, where the last arg is the column to encode. [0] means 1st one\n",
        "# passthrough is used to keep all the other columns\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "\n",
        "# make the transformed array as numpy array, which is expected by ML models\n",
        "X = np.array(ct.fit_transform(X))\n",
        "print(X)"
      ],
      "metadata": {
        "id": "E1OdiNmo3WVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b3bfb5-2a11-44e1-a3a9-a17269b06562"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Dependent Variable, yes and no to 1 and 0\n",
        "\n"
      ],
      "metadata": {
        "id": "V0lUkJqssW9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY75NLGGsSzf",
        "outputId": "0b0cedaf-521d-4c44-e99b-d6ba7da6749d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Splitting\n",
        "- Apply Feature Scaling After Splitting the Data into training and test set.\n",
        "\n",
        "- Test set is supposed to be new\n",
        "- To prevent information Leaking\n"
      ],
      "metadata": {
        "id": "YVT29_tZNPiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# random state = 1 to set the same random factors for all\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
      ],
      "metadata": {
        "id": "rnwpuUPXJV0b"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU8s6lNrQanE",
        "outputId": "365652e1-dcf4-4e71-c531-e131c50a34dd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling\n",
        "- To prevent the domination of one feature over another\n",
        "- Feature Scaling is applied for some ML models, not all.\n",
        "\n",
        "Generally Two technique is user for feature scaling\n",
        "- Standardisation. vlaues [-3 to +3]\n",
        "- Normalization. values [0 to 1]\n",
        "\n",
        "Standardisation works for all models, but normalizaton is good for only certain models/cases. So when we are not use, better to use Standardisation.\n",
        "\n",
        "- Only apply Feature scaling to the numerical variables\n",
        "- Avoid applying in dummy variables,in this case, the <b> Encoded Category </b>"
      ],
      "metadata": {
        "id": "emSCRKcOQqY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply Standardization using Scikit-learn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "# first 2 index are the encoded values for Countries(category). so, exclude them\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "# use only transform method to avoid getting a new scaler for X_test\n",
        "# this way it will apply the same transformer that was used to the training data\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
      ],
      "metadata": {
        "id": "1-K0ulE5Vr0j"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)\n",
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Ietvg5Yiff",
        "outputId": "dd8a6ac5-67cc-4c0f-8adb-37947bbfaca8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n",
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ]
    }
  ]
}